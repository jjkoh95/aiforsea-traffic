{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data preprocessing\n",
    "\n",
    "I tried to be minimalistic. While geohash6 value is converted to distance away from certain point of interests and datetime are engineered into sin/cos equivalent. I try to be logical here and use only previous 2 hours demands and previous 7 days demands of the predicted time window +/- 1 hour.\n",
    "\n",
    "### Data preprocessing and feature engineerings\n",
    "- distance from hand-picked POI - qp09d8, qp03xx, qp03wf\n",
    "- day - day_of_week_sin, day_of_week_cos\n",
    "- hour - hour_sin, hour_cos\n",
    "- fiteen minute - fifteen_minute_sin, fifteen_minute_cos\n",
    "- last two hours demand - demand_t0, demand_t1, ... demand_t7\n",
    "- last seven days demands of the predicted time +/- 1 hour - demand_{day}d_t{ith}\n",
    "- next 5 demands (target_1, ... target_5)\n",
    "\n",
    "## NOTE I HAVE INCLUDED MORE FEATURES THAN MY MODEL ACTUALLY NEEDED AS I WAS TOYING AND EXPERIMENTING WHAT ARE THE BEST FEATURES TO REDUCE COMPLEXITY OF MY MODEL WHILE MAINTAINING A GOOD RMSE/SMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import geohash\n",
    "import gc\n",
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DAY_ONWARDS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/0-df.pkl')\n",
    "train_df = df[df.day <= EVAL_DAY_ONWARDS]\n",
    "eval_df = df[df.day > EVAL_DAY_ONWARDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_hour_minute(timestamp):\n",
    "    timestamp = timestamp.split(':')\n",
    "    return int(timestamp[0]), int(timestamp[1])\n",
    "\n",
    "def get_distance_by_gh(gh1, gh2):\n",
    "    coor1 = geohash.decode(gh1)\n",
    "    coor2 = geohash.decode(gh2)\n",
    "    return distance.distance(coor1, coor2).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_df['hour'] = train_df.timestamp.apply(lambda x: timestamp_to_hour_minute(x)[0])\n",
    "train_df['hour_sin'] = np.sin(train_df.hour*(np.pi/24))\n",
    "train_df['hour_cos'] = np.cos(train_df.hour*(np.pi/24))\n",
    "\n",
    "eval_df['hour'] = eval_df.timestamp.apply(lambda x: timestamp_to_hour_minute(x)[0])\n",
    "eval_df['hour_sin'] = np.sin(eval_df.hour*(np.pi/24))\n",
    "eval_df['hour_cos'] = np.cos(eval_df.hour*(np.pi/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_df['day_mod_seven'] = train_df.day.values % 7\n",
    "train_df['day_of_week_sin'] = np.sin(train_df.day_mod_seven*(np.pi/7))\n",
    "train_df['day_of_week_cos'] = np.cos(train_df.day_mod_seven*(np.pi/7))\n",
    "\n",
    "eval_df['day_mod_seven'] = eval_df.day.values % 7\n",
    "eval_df['day_of_week_sin'] = np.sin(eval_df.day_mod_seven*(np.pi/7))\n",
    "eval_df['day_of_week_cos'] = np.cos(eval_df.day_mod_seven*(np.pi/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_df['per_fifteen_minutes'] = train_df.order.values % 96\n",
    "train_df['fifteen_minute_sin'] = np.sin(train_df.per_fifteen_minutes*(np.pi/96))\n",
    "train_df['fifteen_minute_cos'] = np.cos(train_df.per_fifteen_minutes*(np.pi/96))\n",
    "\n",
    "eval_df['per_fifteen_minutes'] = eval_df.order.values % 96\n",
    "eval_df['fifteen_minute_sin'] = np.sin(eval_df.per_fifteen_minutes*(np.pi/96))\n",
    "eval_df['fifteen_minute_cos'] = np.cos(eval_df.per_fifteen_minutes*(np.pi/96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following parts are to get aggregated values to our model, however they are not making my model better after few trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_dict = {}\n",
    "# for gh in train_df.geohash6.unique():\n",
    "#     temp_df = train_df[train_df.geohash6 == gh]\n",
    "    \n",
    "#     agg_dict[gh] = {}\n",
    "    \n",
    "#     agg_dict[gh]['per_fifteen_minutes_median'] = temp_df.groupby('per_fifteen_minutes').median().demand.values\n",
    "#     agg_dict[gh]['per_fifteen_minutes_mean'] = temp_df.groupby('per_fifteen_minutes').mean().demand.values\n",
    "    \n",
    "#     agg_dict[gh]['hour_median'] = temp_df.groupby('hour').median().demand.values\n",
    "#     agg_dict[gh]['hour_mean'] = temp_df.groupby('hour').median().demand.values\n",
    "    \n",
    "#     agg_dict[gh]['day_mod_seven_median'] = temp_df.groupby('day_mod_seven').median().demand.values\n",
    "#     agg_dict[gh]['day_mod_seven_mean'] = temp_df.groupby('day_mod_seven').mean().demand.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per fifteen_minutes (of that geohash)\n",
    "# train_df['per_fifteen_minutes_median'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['per_fifteen_minutes_median'][x.per_fifteen_minutes], axis=1)\n",
    "# )\n",
    "# train_df['per_fifteen_minutes_mean'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['per_fifteen_minutes_mean'][x.per_fifteen_minutes], axis=1)\n",
    "# )\n",
    "\n",
    "# eval_df['per_fifteen_minutes_median'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['per_fifteen_minutes_median'][x.per_fifteen_minutes], axis=1)\n",
    "# )\n",
    "# eval_df['per_fifteen_minutes_mean'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['per_fifteen_minutes_mean'][x.per_fifteen_minutes], axis=1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # median by hour (of that geohash)\n",
    "# train_df['hour_median'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['hour_median'][x.hour], axis=1)\n",
    "# )\n",
    "# train_df['hour_mean'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['hour_mean'][x.hour], axis=1)\n",
    "# )\n",
    "\n",
    "# eval_df['hour_median'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['hour_median'][x.hour], axis=1)\n",
    "# )\n",
    "# eval_df['hour_mean'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['hour_mean'][x.hour], axis=1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # median by day_mod_seven (of that geohash)\n",
    "# train_df['day_of_week_median'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['day_mod_seven_median'][x.day_mod_seven], axis=1)\n",
    "# )\n",
    "# train_df['day_of_week_mean'] = (\n",
    "#     train_df.apply(lambda x: agg_dict[x.geohash6]['day_mod_seven_mean'][x.day_mod_seven], axis=1)\n",
    "# )\n",
    "\n",
    "# eval_df['day_of_week_median'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['day_mod_seven_median'][x.day_mod_seven], axis=1)\n",
    "# )\n",
    "# eval_df['day_of_week_mean'] = (\n",
    "#     eval_df.apply(lambda x: agg_dict[x.geohash6]['day_mod_seven_mean'][x.day_mod_seven], axis=1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['lat'] = train_df.geohash6.apply(lambda x: geohash.decode(x)[0])\n",
    "# train_df['long'] = train_df.geohash6.apply(lambda x: geohash.decode(x)[1])\n",
    "\n",
    "# eval_df['lat'] = eval_df.geohash6.apply(lambda x: geohash.decode(x)[0])\n",
    "# eval_df['long'] = eval_df.geohash6.apply(lambda x: geohash.decode(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_GEOHASH = ['qp09d8', 'qp03xx', 'qp03wf']\n",
    "poi_distance_dict = {}\n",
    "for poi in POI_GEOHASH:\n",
    "    poi_distance_dict[poi] = {}\n",
    "    for gh in train_df.geohash6.unique():\n",
    "        poi_distance_dict[poi][gh] = get_distance_by_gh(poi, gh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for gh in POI_GEOHASH:\n",
    "    train_df['distance_from_{0}'.format(gh)] = train_df.geohash6.apply(lambda x: poi_distance_dict[gh][x])\n",
    "    eval_df['distance_from_{0}'.format(gh)] = eval_df.geohash6.apply(lambda x: poi_distance_dict[gh][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/grab/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZE\n",
    "for gh in POI_GEOHASH:\n",
    "    gh_key = 'distance_from_{0}'.format(gh)\n",
    "    gh_mean = train_df[gh_key].mean()\n",
    "    gh_std = train_df[gh_key].std()\n",
    "    train_df[gh_key] = (train_df[gh_key] - gh_mean)/gh_std\n",
    "    eval_df[gh_key] = (eval_df[gh_key] - gh_mean)/gh_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.842158336193567, 9.672254418484291)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_mean, gh_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('../data/preprocessed_train_df.pkl')\n",
    "eval_df.to_pickle('../data/preprocessed_eval_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the hard work to transform data into tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.append(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "csv_file = open('../data/preprocessed_df_for_training.csv', 'w')\n",
    "\n",
    "headers = [\n",
    "    'order', 'geohash6', 'day',\n",
    "    'distance_from_qp09d8', 'distance_from_qp03xx', 'distance_from_qp03wf',\n",
    "    'target_1', 'target_2', 'target_3', 'target_4', 'target_5',\n",
    "    'demand_t0', 'demand_t1', 'demand_t2', 'demand_t3', 'demand_t4', 'demand_t5', 'demand_t6', 'demand_t7',\n",
    "    'day_of_week_sin', 'day_of_week_cos',\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'fifteen_minute_sin', 'fifteen_minute_cos',\n",
    "]\n",
    "\n",
    "for d in range(1, 8):\n",
    "    for i in range(13):\n",
    "        headers.append('demand_{0}d_t{1}'.format(d, i))\n",
    "\n",
    "csv_file.write(','.join(headers))\n",
    "csv_file.write('\\n')\n",
    "\n",
    "for i, gh in enumerate(df.geohash6.unique()):\n",
    "    # print(i, len(df.geohash6.unique()))\n",
    "    if i % 100 == 0: print(i)\n",
    "    temp_df = df[df.geohash6 == gh]\n",
    "    temp_df.set_index('order', inplace=True)\n",
    "    start_row = temp_df.index[0]\n",
    "    end_rows = temp_df.index[-1]\n",
    "    for i in range(start_row + 96*7 + 3, end_rows - 5):\n",
    "        # put in whatever data needed into here\n",
    "        arr = {\n",
    "            'order': i,\n",
    "            'geohash6': gh,\n",
    "            'day': temp_df.at[i, 'day'],\n",
    "            \n",
    "            'distance_from_qp09d8': temp_df.at[i, 'distance_from_qp09d8'],\n",
    "            'distance_from_qp03xx': temp_df.at[i, 'distance_from_qp03xx'],\n",
    "            'distance_from_qp03wf': temp_df.at[i, 'distance_from_qp03wf'],\n",
    "            \n",
    "            # LABELS\n",
    "            'target_1': temp_df.at[i+1, 'demand'],\n",
    "            'target_2': temp_df.at[i+2, 'demand'],\n",
    "            'target_3': temp_df.at[i+3, 'demand'],\n",
    "            'target_4': temp_df.at[i+4, 'demand'],\n",
    "            'target_5': temp_df.at[i+5, 'demand'],\n",
    "            \n",
    "            # Last two hours demands\n",
    "            'demand_t0': temp_df.at[i, 'demand'],\n",
    "            'demand_t1': temp_df.at[i-1, 'demand'],\n",
    "            'demand_t2': temp_df.at[i-2, 'demand'],\n",
    "            'demand_t3': temp_df.at[i-3, 'demand'],\n",
    "            'demand_t4': temp_df.at[i-4, 'demand'],\n",
    "            'demand_t5': temp_df.at[i-5, 'demand'],\n",
    "            'demand_t6': temp_df.at[i-6, 'demand'],\n",
    "            'demand_t7': temp_df.at[i-7, 'demand'],\n",
    "            \n",
    "            'day_of_week_sin': temp_df.at[i, 'day_of_week_sin'],\n",
    "            'day_of_week_cos': temp_df.at[i, 'day_of_week_cos'],\n",
    "            \n",
    "            'hour_sin': temp_df.at[i, 'hour_sin'],\n",
    "            'hour_cos': temp_df.at[i, 'hour_cos'],\n",
    "            \n",
    "            'fifteen_minute_sin': temp_df.at[i, 'fifteen_minute_sin'],\n",
    "            'fifteen_minute_cos': temp_df.at[i, 'fifteen_minute_cos'],\n",
    "        }\n",
    "        \n",
    "        for d in range(1, 8):\n",
    "            for j in range(13):\n",
    "                arr['demand_{0}d_t{1}'.format(d, j)] = temp_df.at[i + j - 96*d - 3, 'demand']\n",
    "        \n",
    "        content = []\n",
    "        for h in headers:\n",
    "            content.append(str(arr[h]))\n",
    "        csv_file.write(','.join(content))\n",
    "        csv_file.write('\\n')\n",
    "    gc.collect()\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_df_for_training.csv')\n",
    "df.to_pickle('../data/preprocessed_df_for_training.pkl')\n",
    "df[df.day <= 50].to_pickle('../data/preprocessed_train_df_for_training.pkl')\n",
    "df[df.day > 50].to_pickle('../data/preprocessed_eval_df_for_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
