{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model building\n",
    "\n",
    "## I have toyed a couple configurations of the model and decided to go with this stacked neural network\n",
    "- Last 7 days features go into a RNN\n",
    "- Last 7 days features go into a CNN\n",
    "- Last 2 hours features go into a RNN\n",
    "- Distance/datetime features go in a DNN\n",
    "- Last 7th day features go into a DNN\n",
    "- Outputs of all serve as metadata and feed into a DNN to predict 5 outputs\n",
    "\n",
    "## Hyperparameter\n",
    "- I tried to make this a great balance of complexity and accuracy\n",
    "- The learning rate is difficult as model easily converges into a 'bad' local minima\n",
    "- While I can't guarantee that I have got the global minima, but the results look pretty good to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.1-dev20190607\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    '''RMSE in keras'''\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def symmetric_mean_absolute_mean_error(y_true, y_pred):\n",
    "    '''SMAPE - modified (got it from kaggle)'''\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.nanmean(diff)\n",
    "\n",
    "def calculate_rmse(x, y):\n",
    "    '''RMSE in numpy'''\n",
    "    return np.sum(np.absolute(x - y))/x.shape[0]\n",
    "\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    '''This is just a function wrapper lol'''\n",
    "    return symmetric_mean_absolute_mean_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../data/preprocessed_train_df_for_training.pkl')\n",
    "eval_df = pd.read_pickle('../data/preprocessed_eval_df_for_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feat = [\n",
    "    'distance_from_qp09d8', 'distance_from_qp03xx', 'distance_from_qp03wf',\n",
    "    'day_of_week_sin', 'day_of_week_cos',\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'fifteen_minute_sin', 'fifteen_minute_cos',\n",
    "]\n",
    "\n",
    "last_two_hour_feat = ['demand_t{0}'.format(t) for t in range(8)]\n",
    "\n",
    "last_six_day_feat = []\n",
    "for d in range(1,7):\n",
    "    for i in range(13):\n",
    "        last_six_day_feat.append('demand_{0}d_t{1}'.format(d, i))\n",
    "\n",
    "last_week_today_feat = ['demand_7d_t{0}'.format(i) for i in range(13)]\n",
    "\n",
    "target = ['target_1', 'target_2', 'target_3', 'target_4', 'target_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train_df[raw_feat]\n",
    "X_eval_raw = eval_df[raw_feat]\n",
    "\n",
    "X_train_last_two_hour = train_df[last_two_hour_feat]\n",
    "X_eval_last_two_hour = eval_df[last_two_hour_feat]\n",
    "\n",
    "X_train_last_week = train_df[last_week_today_feat]\n",
    "X_eval_last_week = eval_df[last_week_today_feat]\n",
    "\n",
    "X_train_last_six_day = train_df[last_six_day_feat]\n",
    "X_eval_last_six_day = eval_df[last_six_day_feat]\n",
    "\n",
    "\n",
    "Y_train = train_df[target]\n",
    "Y_eval = eval_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(2019) # make sure keras will get reproducible result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 78)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 91)           0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 7, 13)        0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 7, 16)        1056        reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 91)           0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 4, 16)        0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           640         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 7, 13)        0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 4, 8)         392         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 64)           896         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 8, 1)         0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           2080        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_9 (GRU)                     (None, 7, 32)        4416        reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 2, 8)         0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 32)           2080        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_11 (GRU)                    (None, 8, 32)        3264        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 16)           528         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_10 (GRU)                    (None, 16)           2352        gru_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 16)           528         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_12 (GRU)                    (None, 16)           2352        gru_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 80)           0           dense_23[0][0]                   \n",
      "                                                                 gru_10[0][0]                     \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 dense_26[0][0]                   \n",
      "                                                                 gru_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 64)           5184        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 32)           2080        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 16)           528         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 5)            85          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 28,461\n",
      "Trainable params: 28,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = Input(shape=(len(raw_feat),))\n",
    "last_two_hour_inputs = Input(shape=(len(last_two_hour_feat),))\n",
    "last_week_today_inputs = Input(shape=(len(last_week_today_feat),))\n",
    "last_six_day_inputs = Input(shape=(len(last_six_day_feat),))\n",
    "\n",
    "daily_cnn = concatenate([last_week_today_inputs, last_six_day_inputs])\n",
    "daily_cnn = Reshape((7, len(last_week_today_feat),))(daily_cnn)\n",
    "daily_cnn = Conv1D(16, 5, activation=relu, padding='same')(daily_cnn)\n",
    "daily_cnn = MaxPool1D(2, 2, padding='same')(daily_cnn)\n",
    "daily_cnn = Conv1D(8, 3, activation=relu, padding='same')(daily_cnn)\n",
    "daily_cnn = MaxPool1D(2, 2, padding='same')(daily_cnn)\n",
    "daily_cnn = Flatten()(daily_cnn)\n",
    "daily_cnn = Model(inputs=[last_week_today_inputs, last_six_day_inputs], outputs=daily_cnn)\n",
    "\n",
    "daily_rnn = concatenate([last_week_today_inputs, last_six_day_inputs])\n",
    "daily_rnn = Reshape((7, len(last_week_today_feat),))(daily_rnn)\n",
    "daily_rnn = GRU(32, return_sequences=True)(daily_rnn)\n",
    "daily_rnn = GRU(16)(daily_rnn)\n",
    "daily_rnn = Model(inputs=[last_week_today_inputs, last_six_day_inputs], outputs=daily_rnn)\n",
    "\n",
    "raw_dnn = Dense(64, activation=relu)(raw_inputs)\n",
    "raw_dnn = Dense(32, activation=relu)(raw_dnn)\n",
    "raw_dnn = Dense(16, activation=relu)(raw_dnn)\n",
    "raw_dnn = Model(inputs=raw_inputs, outputs=raw_dnn)\n",
    "\n",
    "attention_dnn = Dense(64, activation=relu)(last_week_today_inputs)\n",
    "attention_dnn = Dense(32, activation=relu)(attention_dnn)\n",
    "attention_dnn = Dense(16, activation=relu)(attention_dnn)\n",
    "attention_dnn = Model(inputs=last_week_today_inputs, outputs=attention_dnn)\n",
    "\n",
    "last_two_hour_rnn = Reshape((len(last_two_hour_feat), 1, ))(last_two_hour_inputs)\n",
    "last_two_hour_rnn = GRU(32, return_sequences=True)(last_two_hour_rnn)\n",
    "last_two_hour_rnn = GRU(16)(last_two_hour_rnn)\n",
    "last_two_hour_rnn = Model(inputs=last_two_hour_inputs, outputs=last_two_hour_rnn)\n",
    "\n",
    "# last_week_today_inputs act as attention\n",
    "final_stacked = concatenate([raw_dnn.output, \n",
    "                             daily_rnn.output, \n",
    "                             daily_cnn.output, \n",
    "                             attention_dnn.output, \n",
    "                             last_two_hour_rnn.output])\n",
    "final_stacked = Dense(64, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(32, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(16, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(5, activation=hard_sigmoid)(final_stacked)\n",
    "final_stacked = Model(inputs=[raw_inputs, last_week_today_inputs, last_six_day_inputs, last_two_hour_inputs],\n",
    "                      outputs=final_stacked)\n",
    "\n",
    "final_stacked.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 360s 66us/step - loss: 8.5403e-04 - root_mean_squared_error: 0.0282 - val_loss: 8.9757e-04 - val_root_mean_squared_error: 0.0222\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 352s 64us/step - loss: 7.5571e-04 - root_mean_squared_error: 0.0271 - val_loss: 8.7603e-04 - val_root_mean_squared_error: 0.0219\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 359s 66us/step - loss: 7.4161e-04 - root_mean_squared_error: 0.0268 - val_loss: 8.7276e-04 - val_root_mean_squared_error: 0.0219\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 353s 64us/step - loss: 7.3873e-04 - root_mean_squared_error: 0.0268 - val_loss: 8.6265e-04 - val_root_mean_squared_error: 0.0218\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 358s 65us/step - loss: 7.2675e-04 - root_mean_squared_error: 0.0266 - val_loss: 8.5889e-04 - val_root_mean_squared_error: 0.0218\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 360s 66us/step - loss: 7.2602e-04 - root_mean_squared_error: 0.0266 - val_loss: 8.5850e-04 - val_root_mean_squared_error: 0.0218\n"
     ]
    }
   ],
   "source": [
    "# While Adagrad has great lr update, but this gives the model a little kick\n",
    "for lr, ep in [(0.01, 1), (0.005, 1), (0.003, 1),\n",
    "               (0.005, 1), (0.0003, 1), (0.0001, 1)]:\n",
    "    final_stacked.compile(optimizer=Adagrad(lr=lr), loss=mean_squared_error, metrics=[root_mean_squared_error],)\n",
    "    final_stacked.fit(\n",
    "        [X_train_raw, X_train_last_week, X_train_last_six_day, X_train_last_two_hour], Y_train,\n",
    "        batch_size=256, epochs=ep,\n",
    "        validation_data=([X_eval_raw, X_eval_last_week, X_eval_last_six_day, X_eval_last_two_hour], Y_eval),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked.save('../model/final_stacked_80.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse(t+1)</th>\n",
       "      <th>rmse(t+2)</th>\n",
       "      <th>rmse(t+3)</th>\n",
       "      <th>rmse(t+4)</th>\n",
       "      <th>rmse(t+5)</th>\n",
       "      <th>smape(t+1)</th>\n",
       "      <th>smape(t+2)</th>\n",
       "      <th>smape(t+3)</th>\n",
       "      <th>smape(t+4)</th>\n",
       "      <th>smape(t+5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1.329000e+03</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1.329000e+03</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012436</td>\n",
       "      <td>1.376487e-02</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>1.498439e-02</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>51.652021</td>\n",
       "      <td>50.591721</td>\n",
       "      <td>50.100544</td>\n",
       "      <td>51.259864</td>\n",
       "      <td>50.680409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011131</td>\n",
       "      <td>1.274595e-02</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>1.444920e-02</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>26.546016</td>\n",
       "      <td>26.096379</td>\n",
       "      <td>26.335638</td>\n",
       "      <td>25.571516</td>\n",
       "      <td>25.539954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.047339e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.841255e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003463</td>\n",
       "      <td>3.632281e-03</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>3.785942e-03</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>32.204681</td>\n",
       "      <td>31.699774</td>\n",
       "      <td>31.008934</td>\n",
       "      <td>32.578618</td>\n",
       "      <td>32.313670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010054</td>\n",
       "      <td>1.071960e-02</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>1.131061e-02</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>51.602022</td>\n",
       "      <td>50.091757</td>\n",
       "      <td>50.462803</td>\n",
       "      <td>51.784532</td>\n",
       "      <td>51.727902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.018477</td>\n",
       "      <td>2.030096e-02</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>2.158792e-02</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>71.597790</td>\n",
       "      <td>69.367944</td>\n",
       "      <td>69.121369</td>\n",
       "      <td>70.181673</td>\n",
       "      <td>69.760072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.062792</td>\n",
       "      <td>8.009573e-02</td>\n",
       "      <td>0.092854</td>\n",
       "      <td>1.016356e-01</td>\n",
       "      <td>0.111073</td>\n",
       "      <td>120.230463</td>\n",
       "      <td>121.409065</td>\n",
       "      <td>114.904273</td>\n",
       "      <td>110.065438</td>\n",
       "      <td>109.557381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse(t+1)     rmse(t+2)    rmse(t+3)     rmse(t+4)    rmse(t+5)  \\\n",
       "count  1329.000000  1.329000e+03  1329.000000  1.329000e+03  1329.000000   \n",
       "mean      0.012436  1.376487e-02     0.014461  1.498439e-02     0.015406   \n",
       "std       0.011131  1.274595e-02     0.013718  1.444920e-02     0.015114   \n",
       "min       0.000000  1.047339e-07     0.000000  5.841255e-08     0.000000   \n",
       "25%       0.003463  3.632281e-03     0.003660  3.785942e-03     0.003778   \n",
       "50%       0.010054  1.071960e-02     0.011083  1.131061e-02     0.011445   \n",
       "75%       0.018477  2.030096e-02     0.021047  2.158792e-02     0.022023   \n",
       "max       0.062792  8.009573e-02     0.092854  1.016356e-01     0.111073   \n",
       "\n",
       "        smape(t+1)   smape(t+2)   smape(t+3)   smape(t+4)   smape(t+5)  \n",
       "count  1329.000000  1329.000000  1329.000000  1329.000000  1329.000000  \n",
       "mean     51.652021    50.591721    50.100544    51.259864    50.680409  \n",
       "std      26.546016    26.096379    26.335638    25.571516    25.539954  \n",
       "min       0.000000     0.190476     0.000000     0.380952     0.000000  \n",
       "25%      32.204681    31.699774    31.008934    32.578618    32.313670  \n",
       "50%      51.602022    50.091757    50.462803    51.784532    51.727902  \n",
       "75%      71.597790    69.367944    69.121369    70.181673    69.760072  \n",
       "max     120.230463   121.409065   114.904273   110.065438   109.557381  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_rmse = []\n",
    "for gh in eval_df.geohash6.unique():\n",
    "    gh_df = eval_df[eval_df.geohash6 == gh]\n",
    "    preds = final_stacked.predict([\n",
    "        gh_df[raw_feat],\n",
    "        gh_df[last_week_today_feat],\n",
    "        gh_df[last_six_day_feat],\n",
    "        gh_df[last_two_hour_feat]\n",
    "    ])\n",
    "    actual = gh_df[target]\n",
    "    stacked_rmse.append({\n",
    "        'geohash6': gh,\n",
    "        'rmse(t+1)': calculate_rmse(actual['target_1'], preds[:, 0]),\n",
    "        'rmse(t+2)': calculate_rmse(actual['target_2'], preds[:, 1]),\n",
    "        'rmse(t+3)': calculate_rmse(actual['target_3'], preds[:, 2]),\n",
    "        'rmse(t+4)': calculate_rmse(actual['target_4'], preds[:, 3]),\n",
    "        'rmse(t+5)': calculate_rmse(actual['target_5'], preds[:, 4]),\n",
    "        'smape(t+1)': calculate_smape(actual['target_1'], preds[:, 0]),\n",
    "        'smape(t+2)': calculate_smape(actual['target_2'], preds[:, 1]),\n",
    "        'smape(t+3)': calculate_smape(actual['target_3'], preds[:, 2]),\n",
    "        'smape(t+4)': calculate_smape(actual['target_4'], preds[:, 3]),\n",
    "        'smape(t+5)': calculate_smape(actual['target_5'], preds[:, 4]),\n",
    "    })\n",
    "stacked_df = pd.DataFrame(stacked_rmse)\n",
    "stacked_df.to_csv('../metrics/stacked_model.csv', index=False)\n",
    "stacked_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predicted plots (Optional)\n",
    "- This part of code will generate predicted values and actual values - just to verify pattern \n",
    "- Don't run if you are only looking to check the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../metrics/target_1\n",
    "!mkdir ../metrics/target_2\n",
    "!mkdir ../metrics/target_3\n",
    "!mkdir ../metrics/target_4\n",
    "!mkdir ../metrics/target_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(5):\n",
    "    t2 = t + 1\n",
    "    print(t, 4)\n",
    "    for TEST_GEOHASH in eval_df.geohash6.unique():\n",
    "        gh_df = eval_df[eval_df.geohash6 == TEST_GEOHASH]\n",
    "        Y_preds = final_stacked.predict([\n",
    "            gh_df[raw_feat],\n",
    "            gh_df[last_week_today_feat],\n",
    "            gh_df[last_six_day_feat],\n",
    "            gh_df[last_two_hour_feat]\n",
    "        ])\n",
    "        figure(num=None, figsize=(25, 6))\n",
    "        x_axis = np.arange(eval_df[eval_df.geohash6 == TEST_GEOHASH].shape[0])\n",
    "        plt.plot(x_axis, Y_eval[eval_df.geohash6 == TEST_GEOHASH]['target_{0}'.format(t2)])\n",
    "        plt.plot(x_axis, Y_preds[:, t])\n",
    "        plt.savefig('../metrics/target_{0}/{1}.png'.format(t2, TEST_GEOHASH))\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more 'powerful' model (training 100% of the data)\n",
    "- this is to evaluate the test/holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/preprocessed_df_for_training.pkl')\n",
    "X_train_raw = df[raw_feat]\n",
    "X_train_last_two_hour = df[last_two_hour_feat]\n",
    "X_train_last_week = df[last_week_today_feat]\n",
    "X_train_last_six_day = df[last_six_day_feat]\n",
    "Y_train = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "6877575/6877575 [==============================] - 443s 64us/step - loss: 7.5148e-04 - root_mean_squared_error: 0.0271\n",
      "Epoch 2/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.5044e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 3/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.5000e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 4/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.4970e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 5/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.4946e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 6/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.4923e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 7/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.4905e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 8/8\n",
      "6877575/6877575 [==============================] - 408s 59us/step - loss: 7.4888e-04 - root_mean_squared_error: 0.0270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc3fb6b630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del final_stacked\n",
    "# final_stacked = load_model('../model/final_stacked_80.h5')\n",
    "final_stacked.compile(optimizer=Adagrad(lr=3e-4), loss=mean_squared_error, metrics=[root_mean_squared_error],)\n",
    "final_stacked.fit(\n",
    "    [X_train_raw, X_train_last_week, X_train_last_six_day, X_train_last_two_hour], Y_train,\n",
    "    batch_size=256, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked.save('../model/final_stacked_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
