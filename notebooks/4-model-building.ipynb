{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model building\n",
    "\n",
    "## I have toyed a couple configurations of the model and decided to go with this stacked neural network\n",
    "- Last 7 days features go into a RNN\n",
    "- Last 7 days features go into a CNN\n",
    "- Last 2 hours features go into a RNN\n",
    "- Distance/datetime features go in a DNN\n",
    "- Last 7th day features go into a DNN\n",
    "- Outputs of all serve as metadata and feed into a DNN to predict 5 outputs\n",
    "\n",
    "## Hyperparameter\n",
    "- I tried to make this a great balance of complexity and accuracy\n",
    "- The learning rate is difficult as model easily converges into a 'bad' local minima\n",
    "- While I can't guarantee that I have got the global minima, but the results look pretty good to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.1-dev20190607\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    '''RMSE in keras'''\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def symmetric_mean_absolute_mean_error(y_true, y_pred):\n",
    "    '''SMAPE - modified (got it from kaggle)'''\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.nanmean(diff)\n",
    "\n",
    "def calculate_rmse(x, y):\n",
    "    '''RMSE in numpy'''\n",
    "    return np.sum(np.absolute(x - y))/x.shape[0]\n",
    "\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    '''This is just a function wrapper lol'''\n",
    "    return symmetric_mean_absolute_mean_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../data/preprocessed_train_df_for_training.pkl')\n",
    "eval_df = pd.read_pickle('../data/preprocessed_eval_df_for_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feat = [\n",
    "    'distance_from_qp09d8', 'distance_from_qp03xx', 'distance_from_qp03wf',\n",
    "    'day_of_week_sin', 'day_of_week_cos',\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'fifteen_minute_sin', 'fifteen_minute_cos',\n",
    "]\n",
    "\n",
    "last_two_hour_feat = ['demand_t{0}'.format(t) for t in range(8)]\n",
    "\n",
    "last_six_day_feat = []\n",
    "for d in range(6, 0, -1):\n",
    "    for i in range(13):\n",
    "        last_six_day_feat.append('demand_{0}d_t{1}'.format(d, i))\n",
    "\n",
    "last_week_today_feat = ['demand_7d_t{0}'.format(i) for i in range(13)]\n",
    "\n",
    "target = ['target_1', 'target_2', 'target_3', 'target_4', 'target_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train_df[raw_feat]\n",
    "X_eval_raw = eval_df[raw_feat]\n",
    "\n",
    "X_train_last_two_hour = train_df[last_two_hour_feat]\n",
    "X_eval_last_two_hour = eval_df[last_two_hour_feat]\n",
    "\n",
    "X_train_last_week = train_df[last_week_today_feat]\n",
    "X_eval_last_week = eval_df[last_week_today_feat]\n",
    "\n",
    "X_train_last_six_day = train_df[last_six_day_feat]\n",
    "X_eval_last_six_day = eval_df[last_six_day_feat]\n",
    "\n",
    "\n",
    "Y_train = train_df[target]\n",
    "Y_eval = eval_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(2019) # make sure keras will get reproducible result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0617 20:54:52.411050 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0617 20:54:52.429888 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0617 20:54:52.589108 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0617 20:54:52.678647 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 78)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 91)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 7, 13)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 7, 16)        1056        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 91)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4, 16)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 7, 13)        0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4, 8)         392         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 8, 1)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 7, 32)        4416        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2, 8)         0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 8, 32)        3264        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 16)           2352        gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           528         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 16)           2352        gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80)           0           dense_3[0][0]                    \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           5184        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           2080        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           528         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            85          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,461\n",
      "Trainable params: 28,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = Input(shape=(len(raw_feat),))\n",
    "last_two_hour_inputs = Input(shape=(len(last_two_hour_feat),))\n",
    "last_week_today_inputs = Input(shape=(len(last_week_today_feat),))\n",
    "last_six_day_inputs = Input(shape=(len(last_six_day_feat),))\n",
    "\n",
    "daily_cnn = concatenate([last_week_today_inputs, last_six_day_inputs])\n",
    "daily_cnn = Reshape((7, len(last_week_today_feat),))(daily_cnn)\n",
    "daily_cnn = Conv1D(16, 5, activation=relu, padding='same')(daily_cnn)\n",
    "daily_cnn = MaxPool1D(2, 2, padding='same')(daily_cnn)\n",
    "daily_cnn = Conv1D(8, 3, activation=relu, padding='same')(daily_cnn)\n",
    "daily_cnn = MaxPool1D(2, 2, padding='same')(daily_cnn)\n",
    "daily_cnn = Flatten()(daily_cnn)\n",
    "daily_cnn = Model(inputs=[last_week_today_inputs, last_six_day_inputs], outputs=daily_cnn)\n",
    "\n",
    "daily_rnn = concatenate([last_week_today_inputs, last_six_day_inputs])\n",
    "daily_rnn = Reshape((7, len(last_week_today_feat),))(daily_rnn)\n",
    "daily_rnn = GRU(32, return_sequences=True)(daily_rnn)\n",
    "daily_rnn = GRU(16)(daily_rnn)\n",
    "daily_rnn = Model(inputs=[last_week_today_inputs, last_six_day_inputs], outputs=daily_rnn)\n",
    "\n",
    "raw_dnn = Dense(64, activation=relu)(raw_inputs)\n",
    "raw_dnn = Dense(32, activation=relu)(raw_dnn)\n",
    "raw_dnn = Dense(16, activation=relu)(raw_dnn)\n",
    "raw_dnn = Model(inputs=raw_inputs, outputs=raw_dnn)\n",
    "\n",
    "attention_dnn = Dense(64, activation=relu)(last_week_today_inputs)\n",
    "attention_dnn = Dense(32, activation=relu)(attention_dnn)\n",
    "attention_dnn = Dense(16, activation=relu)(attention_dnn)\n",
    "attention_dnn = Model(inputs=last_week_today_inputs, outputs=attention_dnn)\n",
    "\n",
    "last_two_hour_rnn = Reshape((len(last_two_hour_feat), 1, ))(last_two_hour_inputs)\n",
    "last_two_hour_rnn = GRU(32, return_sequences=True)(last_two_hour_rnn)\n",
    "last_two_hour_rnn = GRU(16)(last_two_hour_rnn)\n",
    "last_two_hour_rnn = Model(inputs=last_two_hour_inputs, outputs=last_two_hour_rnn)\n",
    "\n",
    "# last_week_today_inputs act as attention\n",
    "final_stacked = concatenate([raw_dnn.output, \n",
    "                             daily_rnn.output, \n",
    "                             daily_cnn.output, \n",
    "                             attention_dnn.output, \n",
    "                             last_two_hour_rnn.output])\n",
    "final_stacked = Dense(64, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(32, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(16, activation=relu)(final_stacked)\n",
    "final_stacked = Dense(5, activation=hard_sigmoid)(final_stacked)\n",
    "final_stacked = Model(inputs=[raw_inputs, last_week_today_inputs, last_six_day_inputs, last_two_hour_inputs],\n",
    "                      outputs=final_stacked)\n",
    "\n",
    "final_stacked.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0617 20:54:54.381494 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0617 20:54:54.678704 4672525760 deprecation.py:323] From /anaconda3/envs/grab/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0617 20:54:57.991411 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0617 20:54:57.995366 4672525760 deprecation_wrapper.py:118] From /anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 552s 101us/step - loss: 8.4808e-04 - root_mean_squared_error: 0.0281 - val_loss: 9.0709e-04 - val_root_mean_squared_error: 0.0224\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 460s 84us/step - loss: 7.5342e-04 - root_mean_squared_error: 0.0270 - val_loss: 8.7338e-04 - val_root_mean_squared_error: 0.0220\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 485s 89us/step - loss: 7.3902e-04 - root_mean_squared_error: 0.0268 - val_loss: 8.6975e-04 - val_root_mean_squared_error: 0.0219\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 489s 89us/step - loss: 7.3648e-04 - root_mean_squared_error: 0.0267 - val_loss: 8.6371e-04 - val_root_mean_squared_error: 0.0219\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 518s 95us/step - loss: 7.2439e-04 - root_mean_squared_error: 0.0265 - val_loss: 8.5923e-04 - val_root_mean_squared_error: 0.0218\n",
      "Train on 5482125 samples, validate on 1395450 samples\n",
      "Epoch 1/1\n",
      "5482125/5482125 [==============================] - 565s 103us/step - loss: 7.2365e-04 - root_mean_squared_error: 0.0265 - val_loss: 8.5967e-04 - val_root_mean_squared_error: 0.0218\n"
     ]
    }
   ],
   "source": [
    "# While Adagrad has great lr update, but this gives the model a little kick\n",
    "for lr, ep in [(0.01, 1), (0.005, 1), (0.003, 1),\n",
    "               (0.005, 1), (0.0003, 1), (0.0001, 1)]:\n",
    "    final_stacked.compile(optimizer=Adagrad(lr=lr), loss=mean_squared_error, metrics=[root_mean_squared_error],)\n",
    "    final_stacked.fit(\n",
    "        [X_train_raw, X_train_last_week, X_train_last_six_day, X_train_last_two_hour], Y_train,\n",
    "        batch_size=256, epochs=ep,\n",
    "        validation_data=([X_eval_raw, X_eval_last_week, X_eval_last_six_day, X_eval_last_two_hour], Y_eval),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked.save('../model/final_stacked_80.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse(t+1)</th>\n",
       "      <th>rmse(t+2)</th>\n",
       "      <th>rmse(t+3)</th>\n",
       "      <th>rmse(t+4)</th>\n",
       "      <th>rmse(t+5)</th>\n",
       "      <th>smape(t+1)</th>\n",
       "      <th>smape(t+2)</th>\n",
       "      <th>smape(t+3)</th>\n",
       "      <th>smape(t+4)</th>\n",
       "      <th>smape(t+5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.014930</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>54.499280</td>\n",
       "      <td>56.121249</td>\n",
       "      <td>53.448223</td>\n",
       "      <td>50.999525</td>\n",
       "      <td>51.463719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>24.251723</td>\n",
       "      <td>24.578328</td>\n",
       "      <td>24.661966</td>\n",
       "      <td>24.693499</td>\n",
       "      <td>23.885323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.004966</td>\n",
       "      <td>3.591056</td>\n",
       "      <td>4.181273</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>37.329588</td>\n",
       "      <td>38.742804</td>\n",
       "      <td>34.679212</td>\n",
       "      <td>32.418798</td>\n",
       "      <td>34.285128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>53.178089</td>\n",
       "      <td>55.457543</td>\n",
       "      <td>53.792007</td>\n",
       "      <td>51.015571</td>\n",
       "      <td>51.472266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.018575</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>72.677631</td>\n",
       "      <td>74.029956</td>\n",
       "      <td>71.746121</td>\n",
       "      <td>68.765498</td>\n",
       "      <td>69.013451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.077622</td>\n",
       "      <td>0.090147</td>\n",
       "      <td>0.097664</td>\n",
       "      <td>0.105954</td>\n",
       "      <td>121.734910</td>\n",
       "      <td>114.803833</td>\n",
       "      <td>109.735817</td>\n",
       "      <td>108.275413</td>\n",
       "      <td>111.023064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse(t+1)    rmse(t+2)    rmse(t+3)    rmse(t+4)    rmse(t+5)  \\\n",
       "count  1329.000000  1329.000000  1329.000000  1329.000000  1329.000000   \n",
       "mean      0.012463     0.013794     0.014497     0.014930     0.015398   \n",
       "std       0.011181     0.012712     0.013749     0.014415     0.015058   \n",
       "min       0.000002     0.000022     0.000027     0.000002     0.000007   \n",
       "25%       0.003428     0.003634     0.003694     0.003632     0.003725   \n",
       "50%       0.010025     0.010733     0.011051     0.011207     0.011441   \n",
       "75%       0.018575     0.020227     0.021094     0.021509     0.021934   \n",
       "max       0.061587     0.077622     0.090147     0.097664     0.105954   \n",
       "\n",
       "        smape(t+1)   smape(t+2)   smape(t+3)   smape(t+4)   smape(t+5)  \n",
       "count  1329.000000  1329.000000  1329.000000  1329.000000  1329.000000  \n",
       "mean     54.499280    56.121249    53.448223    50.999525    51.463719  \n",
       "std      24.251723    24.578328    24.661966    24.693499    23.885323  \n",
       "min       3.004966     3.591056     4.181273     1.333333     2.285714  \n",
       "25%      37.329588    38.742804    34.679212    32.418798    34.285128  \n",
       "50%      53.178089    55.457543    53.792007    51.015571    51.472266  \n",
       "75%      72.677631    74.029956    71.746121    68.765498    69.013451  \n",
       "max     121.734910   114.803833   109.735817   108.275413   111.023064  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_rmse = []\n",
    "for gh in eval_df.geohash6.unique():\n",
    "    gh_df = eval_df[eval_df.geohash6 == gh]\n",
    "    preds = final_stacked.predict([\n",
    "        gh_df[raw_feat],\n",
    "        gh_df[last_week_today_feat],\n",
    "        gh_df[last_six_day_feat],\n",
    "        gh_df[last_two_hour_feat]\n",
    "    ])\n",
    "    actual = gh_df[target]\n",
    "    stacked_rmse.append({\n",
    "        'geohash6': gh,\n",
    "        'rmse(t+1)': calculate_rmse(actual['target_1'], preds[:, 0]),\n",
    "        'rmse(t+2)': calculate_rmse(actual['target_2'], preds[:, 1]),\n",
    "        'rmse(t+3)': calculate_rmse(actual['target_3'], preds[:, 2]),\n",
    "        'rmse(t+4)': calculate_rmse(actual['target_4'], preds[:, 3]),\n",
    "        'rmse(t+5)': calculate_rmse(actual['target_5'], preds[:, 4]),\n",
    "        'smape(t+1)': calculate_smape(actual['target_1'], preds[:, 0]),\n",
    "        'smape(t+2)': calculate_smape(actual['target_2'], preds[:, 1]),\n",
    "        'smape(t+3)': calculate_smape(actual['target_3'], preds[:, 2]),\n",
    "        'smape(t+4)': calculate_smape(actual['target_4'], preds[:, 3]),\n",
    "        'smape(t+5)': calculate_smape(actual['target_5'], preds[:, 4]),\n",
    "    })\n",
    "stacked_df = pd.DataFrame(stacked_rmse)\n",
    "stacked_df.to_csv('../metrics/stacked_model.csv', index=False)\n",
    "stacked_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predicted plots (Optional)\n",
    "- This part of code will generate predicted values and actual values - just to verify pattern \n",
    "- Don't run if you are only looking to check the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df['lat'] = stacked_df.geohash6.apply(lambda x: geohash.decode(x)[0])\n",
    "stacked_df['long'] = stacked_df.geohash6.apply(lambda x: geohash.decode(x)[1])\n",
    "\n",
    "temp_df = df[df.day == d]\n",
    "temp_df = temp_df.groupby('geohash6').mean()\n",
    "figure(num=None, figsize=(8, 6))\n",
    "plt.scatter(stacked_df.lat.values, stacked_df.long.values, c=stacked_df['rmse(t+1)'].values)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../metrics/target_1\n",
    "!mkdir ../metrics/target_2\n",
    "!mkdir ../metrics/target_3\n",
    "!mkdir ../metrics/target_4\n",
    "!mkdir ../metrics/target_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(5):\n",
    "    t2 = t + 1\n",
    "    print(t, 4)\n",
    "    for TEST_GEOHASH in eval_df.geohash6.unique():\n",
    "        gh_df = eval_df[eval_df.geohash6 == TEST_GEOHASH]\n",
    "        Y_preds = final_stacked.predict([\n",
    "            gh_df[raw_feat],\n",
    "            gh_df[last_week_today_feat],\n",
    "            gh_df[last_six_day_feat],\n",
    "            gh_df[last_two_hour_feat]\n",
    "        ])\n",
    "        figure(num=None, figsize=(25, 6))\n",
    "        x_axis = np.arange(eval_df[eval_df.geohash6 == TEST_GEOHASH].shape[0])\n",
    "        plt.plot(x_axis, Y_eval[eval_df.geohash6 == TEST_GEOHASH]['target_{0}'.format(t2)])\n",
    "        plt.plot(x_axis, Y_preds[:, t])\n",
    "        plt.savefig('../metrics/target_{0}/{1}.png'.format(t2, TEST_GEOHASH))\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more 'powerful' model (training 100% of the data)\n",
    "- this is to evaluate the test/holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/preprocessed_df_for_training.pkl')\n",
    "X_train_raw = df[raw_feat]\n",
    "X_train_last_two_hour = df[last_two_hour_feat]\n",
    "X_train_last_week = df[last_week_today_feat]\n",
    "X_train_last_six_day = df[last_six_day_feat]\n",
    "Y_train = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "6877575/6877575 [==============================] - 624s 91us/step - loss: 7.4924e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 2/8\n",
      "6877575/6877575 [==============================] - 687s 100us/step - loss: 7.4812e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 3/8\n",
      "6877575/6877575 [==============================] - 651s 95us/step - loss: 7.4770e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 4/8\n",
      "6877575/6877575 [==============================] - 672s 98us/step - loss: 7.4736e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 5/8\n",
      "6877575/6877575 [==============================] - 636s 92us/step - loss: 7.4712e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 6/8\n",
      "6877575/6877575 [==============================] - 739s 107us/step - loss: 7.4691e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 7/8\n",
      "6877575/6877575 [==============================] - 680s 99us/step - loss: 7.4671e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 8/8\n",
      "6245888/6877575 [==========================>...] - ETA: 57s - loss: 7.4674e-04 - root_mean_squared_error: 0.0270"
     ]
    }
   ],
   "source": [
    "final_stacked.compile(optimizer=Adagrad(lr=3e-4), loss=mean_squared_error, metrics=[root_mean_squared_error],)\n",
    "final_stacked.fit(\n",
    "    [X_train_raw, X_train_last_week, X_train_last_six_day, X_train_last_two_hour], Y_train,\n",
    "    batch_size=256, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked.save('../model/final_stacked_100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More epochs! (do not see any significant improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "6877575/6877575 [==============================] - 610s 89us/step - loss: 7.4872e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 2/32\n",
      "6877575/6877575 [==============================] - 490s 71us/step - loss: 7.4845e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 3/32\n",
      "6877575/6877575 [==============================] - 521s 76us/step - loss: 7.4834e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 4/32\n",
      "6877575/6877575 [==============================] - 598s 87us/step - loss: 7.4826e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 5/32\n",
      "6877575/6877575 [==============================] - 537s 78us/step - loss: 7.4819e-04 - root_mean_squared_error: 0.0270\n",
      "Epoch 6/32\n",
      "2784256/6877575 [===========>..................] - ETA: 7:11 - loss: 7.4919e-04 - root_mean_squared_error: 0.0270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e408382e49b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m final_stacked.fit(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mX_train_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_last_week\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_last_six_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_last_two_hour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     batch_size=256, epochs=32)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/grab/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/grab/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/grab/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/grab/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_stacked.compile(optimizer=Adagrad(lr=1e-4), loss=mean_squared_error, metrics=[root_mean_squared_error],)\n",
    "final_stacked.fit(\n",
    "    [X_train_raw, X_train_last_week, X_train_last_six_day, X_train_last_two_hour], Y_train,\n",
    "    batch_size=256, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
